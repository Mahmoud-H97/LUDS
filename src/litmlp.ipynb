{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path as P\n",
    "\n",
    "# Vanilla PyTorch\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Torchvision for CV\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "# PyTorch Lightning\n",
    "import lightning.pytorch as pl\n",
    "import torchmetrics\n",
    "\n",
    "# Logging\n",
    "from lightning.pytorch.loggers import CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y', 'Z', 'intensity', 'return_number', 'number_of_returns', 'synthetic', 'key_point', 'withheld', 'overlap', 'scanner_channel', 'scan_direction_flag', 'edge_of_flight_line', 'classification', 'user_data', 'scan_angle', 'point_source_id', 'gps_time', 'red', 'green', 'blue', 'nir', 'Amplitude', 'Reflectance', 'Deviation']\n"
     ]
    }
   ],
   "source": [
    "# Height -> AHN\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import laspy as lp\n",
    "import os \n",
    "# os.chdir(r'/tudelft.net/staff-umbrella/EDT Veluwe/testbed/AHN/')\n",
    "os.chdir(r'/home/mahmoudahmed/Downloads')\n",
    "\n",
    "# tr_pcd = lp.read(\"C_27DN1.LAZ\")\n",
    "tr_pcd = lp.read(\"33CN2_13.LAZ\")\n",
    "\n",
    "print([dimension.name for dimension in tr_pcd.point_format.dimensions])\n",
    "# print(np.max(tr_pcd.green))\n",
    "points = np.vstack((tr_pcd.x, tr_pcd.y, tr_pcd.z)).transpose()\n",
    "colors = np.vstack((tr_pcd.red, tr_pcd.green, tr_pcd.blue)).transpose()\n",
    "\n",
    "point_clouds = o3d.geometry.PointCloud()\n",
    "point_clouds.points = o3d.utility.Vector3dVector(points)\n",
    "point_clouds.colors = o3d.utility.Vector3dVector(colors/255) \n",
    "\n",
    "o3d.visualization.draw_geometries([point_clouds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer failed to load again!\n"
     ]
    }
   ],
   "source": [
    "# RGB -> Airal \n",
    "\n",
    "from qgis.core import QgsRasterLayer\n",
    "from qgis.core import QgsProject  \n",
    "from PyQt5.QtCore import QFileInfo\n",
    "import os\n",
    "os.chdir(r'/home/mahmoudahmed/Downloads/')\n",
    "file = '2023_182000_461000_RGB_hrl.ecw'\n",
    "fileInfo = QFileInfo(file)\n",
    "baseName = fileInfo.baseName()\n",
    "rlayer = QgsRasterLayer(file, baseName)\n",
    "if not rlayer.isValid():\n",
    "    print (\"Layer failed to load again!\")\n",
    "else:\n",
    "    print (rlayer.renderer())\n",
    "    print (rlayer.renderer().type())\n",
    "    if hasattr(rlayer, \"setCacheImage\"):\n",
    "        rlayer.setCacheImage(None)\n",
    "    rlayer.triggerRepaint()\n",
    "\n",
    "# Add the layer to the Layers panel\n",
    "# QgsMapLayerRegistry.instance().addMapLayer(rlayer)\n",
    "    QgsProject.instance().addMapLayer(rlayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from osgeo import gdal\n",
    "print(gdal.GetDriverByName('ECW'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove slow mirror from list of MNIST mirrors\n",
    "MNIST.mirrors = [\n",
    "    mirror for mirror in MNIST.mirrors if not mirror.startswith(\"http://yann.lecun.com\")\n",
    "]\n",
    "pyqt\n",
    "\n",
    "class LitMLP(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, in_dims, n_classes=10, n_layer_1=128, n_layer_2=256, lr=1e-3):\n",
    "        super().__init__()\n",
    "\n",
    "        # we flatten the input Tensors and pass them through an MLP\n",
    "        self.layer_1 = nn.Linear(np.prod(in_dims), n_layer_1)\n",
    "        self.layer_2 = nn.Linear(n_layer_1, n_layer_2)\n",
    "        self.layer_3 = nn.Linear(n_layer_2, n_classes)\n",
    "\n",
    "        # log hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # compute the accuracy -- no need to roll your own!\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.valid_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines a forward pass using the Stem-Learner-Task\n",
    "        design pattern from Deep Learning Design Patterns:\n",
    "        https://www.manning.com/books/deep-learning-design-patterns\n",
    "        \"\"\"\n",
    "        batch_size, *dims = x.size()\n",
    "\n",
    "        # stem: flatten\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "\n",
    "        # task: compute class logits\n",
    "        x = self.layer_3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # convenient method to get the loss on a batch\n",
    "    def loss(self, xs, ys):\n",
    "        logits = self(xs)  # this calls self.forward\n",
    "        loss = F.nll_loss(logits, ys)\n",
    "        return logits, loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        xs, ys = batch\n",
    "        logits, loss = self.loss(xs, ys)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "\n",
    "        # logging metrics we calculated by hand\n",
    "        self.log(\"train/loss\", loss, on_epoch=True)\n",
    "        # logging a pl.Metric\n",
    "        self.train_acc(preds, ys)\n",
    "        self.log(\"train/acc\", self.train_acc, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "        # task: compute class logits\n",
    "        x = self.layer_3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # convenient method to get the loss on a batch\n",
    "    def loss(self, xs, ys):\n",
    "        logits = self(xs)  # this calls self.forward\n",
    "        loss = F.nll_loss(logits, ys)\n",
    "        return logits, loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        xs, ys = batch\n",
    "        logits, loss = self.loss(xs, ys)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "\n",
    "        # logging metrics we calculated by hand\n",
    "        self.log(\"train/loss\", loss, on_epoch=True)\n",
    "        # logging a pl.Metric\n",
    "        self.train_acc(preds, ys)\n",
    "        self.log(\"train/acc\", self.train_acc, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams[\"lr\"])\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        xs, ys = batch\n",
    "        logits, loss = self.loss(xs, ys)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "\n",
    "        self.test_acc(preds, ys)\n",
    "        self.log(\"test/loss_epoch\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"test/acc_epoch\", self.test_acc, on_step=False, on_epoch=True)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        dummy_input = torch.zeros(self.hparams[\"in_dims\"], device=self.device)\n",
    "        model_filename = \"output/model_final.onnx\"\n",
    "        self.to_onnx(model_filename, dummy_input, export_params=True)\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        xs, ys = batch\n",
    "        logits, loss = self.loss(xs, ys)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "        self.valid_acc(preds, ys)\n",
    "\n",
    "        self.log(\"valid/loss_epoch\", loss)  # default on val/test is on_epoch only\n",
    "        self.log(\"valid/acc_epoch\", self.valid_acc)\n",
    "\n",
    "        self.validation_step_outputs.append(logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        validation_step_outputs = self.validation_step_outputs\n",
    "        flattened_logits = torch.flatten(torch.cat(validation_step_outputs))\n",
    "        # Log metrics to CSV file\n",
    "        self.logger.log_metrics(\n",
    "            {\n",
    "                \"valid/logits\": flattened_logits.mean().item(),\n",
    "                \"global_step\": self.global_step,\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams[\"lr\"])\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        xs, ys = batch\n",
    "        logits, loss = self.loss(xs, ys)\n",
    "        preds = torch.argmax(logits, 1)lf.log(\"test/acc_epoch\", self.test_acc, on_step=False, on_epoch=True)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        dummy_input = torch.zeros(self.hparams[\"in_dims\"], device=self.device)\n",
    "        model_filename = \"output/model_final.onnx\"\n",
    "        self.to_onnx(model_filename, dummy_input, export_params=True)\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        xs, ys = batch\n",
    "        logits, loss = self.loss(xs, ys)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "        self.valid_acc(preds, ys)\n",
    "\n",
    "        self.log(\"valid/loss_epoch\", loss)  # default on val/test is on_epoch only\n",
    "        self.log(\"valid/acc_epoch\", self.valid_acc)\n",
    "\n",
    "        self.validation_step_outputs.append(logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        validation_step_outputs = self.validation_step_outputs\n",
    "        flattened_logits = torch.flatten(torch.cat(validation_step_outputs))\n",
    "        # Log metrics to CSV file\n",
    "        self.logger.log_metrics(\n",
    "            {\n",
    "                \"valid/logits\": flattened_logits.mean().item(),\n",
    "                \"global_step\": self.global_step,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.test_acc(preds, ys)\n",
    "        self.log(\"test/loss_epoch\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"test/acc_epoch\", self.test_acc, on_step=False, on_epoch=True)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        dummy_input = torch.zeros(self.hparams[\"in_dims\"], device=self.device)\n",
    "        model_filename = \"output/model_final.onnx\"\n",
    "        self.to_onnx(model_filename, dummy_input, export_params=True)\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        xs, ys = batch\n",
    "        logits, loss = self.loss(xs, ys)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "        self.valid_acc(preds, ys)\n",
    "\n",
    "        self.log(\"valid/loss_epoch\", loss)  # default on val/test is on_epoch only\n",
    "        self.log(\"valid/acc_epoch\", self.valid_acc)\n",
    "\n",
    "        self.validation_step_outputs.append(logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        validation_step_outputs = self.validation_step_outputs\n",
    "        flattened_logits = torch.flatten(torch.cat(validation_step_outputs))\n",
    "        # Log metrics to CSV file\n",
    "        self.logger.log_metrics(\n",
    "            {\n",
    "                \"valid/logits\": flattened_logits.mean().item(),\n",
    "                \"global_step\": self.global_step,\n",
    "            }\n",
    "        )\n",
    "\n",
    "   # learner: two fully-connected layers\n",
    "        x = F.relu(self.layer_1(x))\n",
    "        x = F.relu(self.layer_2(x))\n",
    "\n",
    "        # task: compute class logits\n",
    "        x = self.layer_3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "lf.log(\"test/acc_epoch\", self.test_acc, on_step=False, on_epoch=True)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        dummy_input = torch.zeros(self.hparams[\"in_dims\"], device=self.device)\n",
    "        model_filename = \"output/model_final.onnx\"\n",
    "        self.to_onnx(model_filename, dummy_input, export_params=True)\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        xs, ys = batch\n",
    "        logits, loss = self.loss(xs, ys)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "        self.valid_acc(preds, ys)\n",
    "\n",
    "        self.log(\"valid/loss_epoch\", loss)  # default on val/test is on_epoch only\n",
    "        self.log(\"valid/acc_epoch\", self.valid_acc)\n",
    "\n",
    "        self.validation_step_outputs.append(logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        validation_step_outputs = self.validation_step_outputs\n",
    "        flattened_logits = torch.flatten(torch.cat(validation_step_outputs))\n",
    "        # Log metrics to CSV file\n",
    "        self.logger.log_metrics(\n",
    "            {\n",
    "                \"valid/logits\": flattened_logits.mean().item(),\n",
    "                \"global_step\": self.global_step,\n",
    "            }\n",
    "        )\n",
    "    # convenient method to get the loss on a batch\n",
    "    def loss(self, xs, ys):\n",
    "        logits = self(xs)  # this calls self.forward\n",
    "        loss = F.nll_loss(logits, ys)\n",
    "        return logits, loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        xs, ys = batch\n",
    "        logits, loss = self.loss(xs, ys)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "\n",
    "        # logging metrics we calculated by hand\n",
    "        self.log(\"train/loss\", loss, on_epoch=True)\n",
    "        # logging a pl.Metric\n",
    "        self.train_acc(preds, ys)\n",
    "        self.log(\"train/acc\", self.train_acc, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams[\"lr\"])\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        xs, ys = batch\n",
    "        logits, loss = self.loss(xs, ys)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "\n",
    "        self.test_acc(preds, ys)\n",
    "        self.log(\"test/loss_epoch\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"test/acc_epoch\", self.test_acc, on_step=False, on_epoch=True)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        dummy_input = torch.zeros(self.hparams[\"in_dims\"], device=self.device)\n",
    "        model_filename = \"output/model_final.onnx\"\n",
    "        self.to_onnx(model_filename, dummy_input, export_params=True)\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        xs, ys = batch\n",
    "        logits, loss = self.loss(xs, ys)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "        self.valid_acc(preds, ys)\n",
    "\n",
    "        self.log(\"valid/loss_epoch\", loss)  # default on val/test is on_epoch only\n",
    "        self.log(\"valid/acc_epoch\", self.valid_acc)\n",
    "\n",
    "        self.validation_step_outputs.append(logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        validation_step_outputs = self.validation_step_outputs\n",
    "        flattened_logits = torch.flatten(torch.cat(validation_step_outputs))\n",
    "        # Log metrics to CSV file\n",
    "        self.logger.log_metrics(\n",
    "            {\n",
    "                \"valid/logits\": flattened_logits.mean().item(),\n",
    "                \"global_step\": self.global_step,\n",
    "            }\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
